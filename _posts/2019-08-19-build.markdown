---
layout: post
title:  "The Accelerator's Build System"
date:   2019-08-01 00:00:00
categories: examples
---

This post describes the basics of the Accelerator's build system, how
it works, why it is designed the way it is, and how it can be used to
_reduce both execution time and probability of making mistakes_.

This is an overview article.  Please see the Accelerator's User's
Reference for details.

### Building a Job

The _job_ is the atomic unit of program execution on the
Accelerator.  "Building a job" means executing a piece of code.  All
information associated with a job is stored in a job specific
directory to be used at any time.  The return value from a job build
operation is a reference to such a directory.

A job is only built if it has not been built before, see
figure

<p align="center"><img src="{{ site.url }}/assets/build_timeline.svg"> </p>

To know if the job has been built before, the Accelerator keeps a
database containing information on all successfully completed build
requests.  This information includes a hash digest of each job's
source code, and is sufficient to uniquely define any job.  Each
build request is compared to this database.



### Inputs to the Build Call
There are three types of input to a job at build time:

 - the program source code,
 - references to input data, and
 - input parameters (i.e. options).

All of these are used to check if a job has been built already.


### Building Process

When a job is built, the following happens:

  1. A new job directory is created.
  2. Everything needed to execute the job is copied into the job directory.
  3. New processes are forked that learns what to do by reading
     the information stored in the job directory.
  4. The new job is executing and output is stored in the job
     directory.
  5. When the job completes, additional profiling information is
     stored in the job directory.

Thus, everything related to a job be found in its job directory.  Jobs
are transparent and easily observable.

<!-- #On a higher level, job directories can be separated into different -->
<!-- #_work directories_, physically separating different tasks or users for -->
<!-- #example. -->



### Job Dependencies
A more complicated task is simpler to write, test, and maintain if it
is separated into several jobs.  Making jobs depend on each other is
straightforward, since references to successfully completed jobs can
be input parameters to new jobs.  Using job references it is possible
to build any kind of directed job flow graph to solve complex
problems.

<p align="center"><img src="{{ site.url }}/assets/build_jobgraph.svg"> </p>



### Datasets and Parallel Data Processing
Although it is not the key focus of this post, it should be mentioned
that jobs could also be data containers.  The Accelerator's _dataset_,
capable of efficiently storing billions of rows of data with ease, is
build on top of the jobs paradigm.  Having jobs referencing eachother
is then used to extend datasets, either with new columns or with new
rows, with minimal overhead.  But this is the topic of another post,
and full details are found in the Accelerator's manual.




### Why this Build System?
The Accelerator's build system is designed for _reproducibility_.  The
same input to the same program should lead to the same output --
always.  There is no need to build a job that shares the same inputs
and source code as an already built job, since the output will be the
same.  If nothing has been changed since the last run, old results
could be looked up and returned immediately.  It typically saves a
significant amount of execution time to re-use old results instead of
re-computing them.

The way the Accelerator's build system works has several advantages



#### All Information About a Job is Stored Together in a Single Directory
Having all results, source code, parameters, and profiling information
in one place is great for observability and transparency.  Looking
into a job directory makes it totally clear which program, parameter
set, and input data that was used to generate a particular result.



#### Jobs are Only Built if not Built Before
This saves time and energy.  Completed jobs will be _re-used_ if
possible.  A re-use might never happen, or it may happen very
frequently.  During the code development phase, for example, re-use
will happen very frequently and long chains of code can be written
without any particular penalty in execution time.

This is somewhat similar to "Makefiles", with a main
difference that all previous "makes" are stored in job directories to
be fetched immediately when called for.  This is efficient for example
during the code development phase, since only modified parts will need
re-execution, and going back and forth between source code versions
does not consume any human measurable execution time.



#### Only Jobs Depending on a Modified Job are Re-Built
A change in the source code will only affect the current job and the
jobs depending on it.  Only those parts that are affected by the
change will be re-executed, which saves time.



#### The Build System Ensures that Parts Affected by a Modification will be Re-Executed
The build system makes sure that parts affected by a change will be
re-executed.  So assuming the build script has been run after any
modifications, the output will be up to date with the modification.


<!-- #### Validation, Does This Output Correspond to this Program/Data/Parameters? -->
<!-- A build script can be run at any time to retrieve references to all -->
<!-- jobs built by it.  Thus, by reading the script and checking the -->
<!-- referenced job directories, it is clear what input and parameters that -->
<!-- are in use to create a certain output. -->

<!-- It answers questions like these -->

<!--  - **"- Did I run this script before or after the code change?"**  Just run -->
<!--     the build script and see what happens.  It if returns immediately -->
<!--     it is up to date.  If some jobs are re-executed, there was a -->
<!--     modification in the source code that was made after the last run. -->
	
<!--  - **"- Does this output take the latest data into account?"** -->
<!--    Again, read and the run the script and see. -->


### What are the Benefits?
The main benefits with the build system is that it brings
_reproducibility_.  Code will only be run if necessary, otherwise
existing results will be used, which saves execution time.  Since
changes that could affect a job's output are taken inte account in the
dependency checking process, jobs _will_ be re-executed if there are
modifications.  The user can verify and know that the used input data
and code is really responsible for the current output.


### Conclusion
